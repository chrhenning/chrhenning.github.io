---
---

@article{henning:2018:estimating,
bibtex_show={true},
	title = {Estimating the information gap between textual and visual representations},
	volume = {7},
	issn = {2192-662X},
	doi = {10.1007/s13735-017-0142-y},
	number = {1},
	journal = {International Journal of Multimedia Information Retrieval},
	author = {Henning, Christian and Ewerth, Ralph},
	year = {2018},
	pages = {43--56},
  google_scholar_id={d1gkVwhDpl0C},
  abstract={To convey a complex matter, it is often beneficial to leverage two or more modalities. For example, slides are utilized to supplement an oral presentation, or photographs, drawings, figures, etc. are exploited in online news or scientific publications to complement textual information. However, the utilization of different modalities and their interrelations can be quite diverse. Sometimes, the transfer of information or knowledge may even be not eased, for instance, in case of contradictory information. The variety of possible interrelations of textual and graphical information and the question, how they can be described and automatically estimated have not been addressed yet by previous work. In this paper, we present several contributions to close this gap. First, we introduce two measures to describe two different dimensions of cross-modal interrelations: cross-modal mutual information (CMI) and semantic correlation (SC). Second, two novel deep learning systems are suggested to estimate CMI and SC of textual and visual information. The first deep neural network consists of an autoencoder that maps images and texts onto a multimodal embedding space. This representation is then exploited in order to train classifiers for SC and CMI. An advantage of this representation is that only a small set of labeled training examples is required for the supervised learning process. Third, three different and large datasets are combined for autoencoder training to increase the diversity of (unlabeled) image–text pairs such that they properly capture the broad range of possible interrelations. Fourth, experimental results are reported for a challenging dataset. Finally, we discuss several applications for the proposed system and outline areas for future work.},
  code={https://github.com/chrhenning/image_text_relation},
  preview={decoder.png},
}
%url = {https://doi.org/10.1007/s13735-017-0142-y},

@inproceedings{henning:2017:estimating,
  bibtex_show={true},
  author = {Henning, Christian and Ewerth, Ralph},
  title = {Estimating the Information Gap between Textual and Visual Representations},
  year = {2017},
  isbn = {9781450347013},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3078971.3078991},
  booktitle = {Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval},
  pages = {14–22},
  numpages = {9},
  location = {Bucharest, Romania},
  series = {ICMR '17},
  additional_info={. *(Best Multimodal Paper Award)*},
  abstract={Photos, drawings, figures, etc. supplement textual information in various kinds of media, for example, in web news or scientific publications. In this respect, the intended effect of an image can be quite different, e.g., providing additional information, focusing on certain details of surrounding text, or simply being a general illustration of a topic. As a consequence, the semantic correlation between information of different modalities can vary noticeably, too. Moreover, cross-modal interrelations are often hard to describe in a precise way. The variety of possible interrelations of textual and graphical information and the question, how they can be described and automatically estimated have not been addressed yet by previous work. In this paper, we present several contributions to close this gap. First, we introduce two measures to describe cross-modal interrelations: cross-modal mutual information (CMI) and semantic correlation (SC). Second, a novel approach relying on deep learning is suggested to estimate CMI and SC of textual and visual information. Third, three diverse datasets are leveraged to learn an appropriate deep neural network model for the demanding task. The system has been evaluated on a challenging test set and the experimental results demonstrate the feasibility of the approach.},
  code={https://github.com/chrhenning/image_text_relation},
  preview={encoder.png},
  abbr={ICMR 2017},
}
%url = {https://doi.org/10.1145/3078971.3078991},

@inproceedings{oshg2019hypercl,
  bibtex_show={true},
  title={Continual learning with hypernetworks},
  author={Johannes von Oswald* and Christian Henning* and Benjamin F. Grewe and Jo{\~a}o Sacramento},
  booktitle={International Conference on Learning Representations},
  year={2020},
  video={https://iclr.cc/virtual_2020/poster_SJgwNerKvB.html},
  code={https://github.com/chrhenning/hypercl},
  arxiv={1906.00695},
  annotation={* Equal contribution. Listing order is random.},
  abbr={ICLR 2020},
  google_scholar_id={2osOgNQ5qMEC},
  abstract={Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less difficult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-specific weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-of-the-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10/100 image datasets.},
  additional_info={. *(Spotlight)*},
  preview={permuted_mnist_100_cl3.pdf},
}

@inproceedings{ehret2020recurrenthypercl,
  bibtex_show={true},
  title={Continual Learning in Recurrent Neural Networks},
  author={Benjamin Ehret* and Christian Henning* and Maria R. Cervera* and Alexander Meulemans and Johannes von Oswald and Benjamin F. Grewe},
  booktitle={International Conference on Learning Representations},
  year={2021},
  video={https://www.youtube.com/watch?v=sFNAXF8H0IY},
  abbr={ICLR 2021},
  annotation={* Equal contribution. Listing order is random.},
  poster={ICLR2021RNNPosterLandscape.pdf},
  preview={dim_per_ts.pdf},
  google_scholar_id={qjMakFHDy7sC},
  abstract={While a diverse collection of continual learning (CL) methods has been proposed to prevent catastrophic forgetting, a thorough investigation of their effectiveness for processing sequential data with recurrent neural networks (RNNs) is lacking. Here, we provide the first comprehensive evaluation of established CL methods on a variety of sequential data benchmarks. Specifically, we shed light on the particularities that arise when applying weight-importance methods, such as elastic weight consolidation, to RNNs. In contrast to feedforward networks, RNNs iteratively reuse a shared set of weights and require working memory to process input samples. We show that the performance of weight-importance methods is not directly affected by the length of the processed sequences, but rather by high working memory requirements, which lead to an increased need for stability at the cost of decreased plasticity for learning subsequent tasks. We additionally provide theoretical arguments supporting this interpretation by studying linear RNNs. Our study shows that established CL methods can be successfully ported to the recurrent case, and that a recent regularization approach based on hypernetworks outperforms weight-importance methods, thus emerging as a promising candidate for CL in RNNs. Overall, we provide insights on the differences between CL in feedforward networks and RNNs, while guiding towards effective solutions to tackle CL on sequential data.},
  arxiv={2006.12109},
  code={https://github.com/mariacer/cl_in_rnns},
}
% url={https://arxiv.org/abs/2006.12109}

@inproceedings{oswald2021late:phase:weights,
  bibtex_show={true},
  title={Neural networks with late-phase weights},
  author={Johannes Von Oswald* and Seijin Kobayashi* and Joao Sacramento and Alexander Meulemans and Christian Henning and Benjamin F Grewe},
  booktitle={International Conference on Learning Representations},
  year={2021},
  abbr={ICLR 2021},
  google_scholar_id={UeHWp8X0CEIC},
  abstract={The largely successful method of training neural networks is to learn their weights using some variant of stochastic gradient descent (SGD). Here, we show that the solutions found by SGD can be further improved by ensembling a subset of the weights in late stages of learning. At the end of learning, we obtain back a single model by taking a spatial average in weight space. To avoid incurring increased computational costs, we investigate a family of low-dimensional late-phase weight models which interact multiplicatively with the remaining parameters. Our results show that augmenting standard models with late-phase weights improves generalization in established benchmarks such as CIFAR-10/100, ImageNet and enwik8. These findings are complemented with a theoretical analysis of a noisy quadratic problem which provides a simplified picture of the late phases of neural network learning.},
  arxiv={2007.12927},
  code={https://github.com/seijin-kobayashi/late-phase-weights},
  annotation={* Equal contribution. Listing order is random.},
  preview={nested_SGD.pdf},
}
% url={https://openreview.net/forum?id=C0qJUx5dxFb}


@inproceedings{posterior:replay:2021:henning:cervera,
  selected={true},
  bibtex_show={true},
  title={Posterior Meta-Replay for Continual Learning},
  author={Christian Henning* and Maria R. Cervera* and Francesco D'Angelo and Johannes von Oswald and Regina Traber and Benjamin Ehret and Seijin Kobayashi and Benjamin F. Grewe and João Sacramento},
  booktitle={Conference on Neural Information Processing Systems},
  year={2021},
  arxiv={2103.01133},
  preview={regression.pdf},
  google_scholar_id={Tyk-4Ss8FVUC},
  video={https://www.youtube.com/watch?v=IF5twAVZ4Ns},
  abstract={Learning a sequence of tasks without access to i.i.d. observations is a widely studied form of continual learning (CL) that remains challenging. In principle, Bayesian learning directly applies to this setting, since recursive and one-off Bayesian updates yield the same result. In practice, however, recursive updating often leads to poor trade-off solutions across tasks because approximate inference is necessary for most models of interest. Here, we describe an alternative Bayesian approach where task-conditioned parameter distributions are continually inferred from data. We offer a practical deep learning implementation of our framework based on probabilistic task-conditioned hypernetworks, an approach we term posterior meta-replay. Experiments on standard benchmarks show that our probabilistic hypernetworks compress sequences of posterior parameter distributions with virtually no forgetting. We obtain considerable performance gains compared to existing Bayesian CL methods, and identify task inference as our major limiting factor. This limitation has several causes that are independent of the considered sequential setting, opening up new avenues for progress in CL.},
  abbr={NeurIPS 2021},
  annotation={* Equal contribution. Listing order is random.},
  poster={NeurIPS2021_PR_CL_Poster.pdf},
  code={https://github.com/chrhenning/posterior_replay_cl},
}

@inproceedings{henning2018approximating:pred:post,
bibtex_show={true},
  title={Approximating the predictive distribution via adversarially-trained hypernetworks},
  author={Christian Henning* and Johannes von Oswald* and Jo{\~a}o Sacramento and Simone Carlo Surace and Jean-Pascal Pfister and Benjamin F. Grewe},
  booktitle={NeurIPS Workshop on Bayesian Deep Learning},
  year={2018},
  annotation={* Equal contribution. Listing order is random.},
  preview={toy_regression_illustrator.png},
  poster={BDL18Poster.pdf},
  abbr={NIPS 2018 BDL},
  additional_info={. *(Spotlight)*},
  abstract={Being able to model uncertainty is a vital property for any intelligent agent. In an environment in which the domain of input stimuli is fully controlled neglecting uncertainty may work, but this usually does not hold true for any real-world scenario. This highlights the necessity for learning algorithms that robustly detect noisy and out-of-distribution examples. Here we propose a novel approach for uncertainty estimation based on adversarially trained hypernetworks. We define a weight posterior to uniformly allow weight realizations of a neural network that meet a chosen fidelity constraint. This setting gives rise to a posterior predictive distribution that allows inference on unseen data samples. In this work, we train a combination of hypernetwork and main network via the GAN framework by sampling from this posterior predictive distribution. Due to the indirect training of the hypernetwork our method does not suffer from complicated loss formulations over weight configurations. We report empirical results that show that our method is able to capture uncertainty over outputs and exhibits performance that is on par with previous work. Furthermore, the use of hypernetworks allows producing arbitrarily complex, multi-modal weight posteriors.},
  google_scholar_id={u-x6o8ySG0sC},
}

@inproceedings{henning:dangelo:2021:bayesian:ood,
  bibtex_show={true},
  title={Are Bayesian neural networks intrinsically good at out-of-distribution detection?},
  author={Christian Henning* and Francesco D'Angelo* and Benjamin F. Grewe},
  booktitle={ICML Workshop on Uncertainty and Robustness in Deep Learning},
  year={2021},
  arxiv={2107.12248},
  preview={gp_post_samples_rbf_1.pdf},
  code={https://github.com/chrhenning/uncertainty_based_ood/tree/master},
  google_scholar_id={Y0pCki6q_DkC},
  abstract={The need to avoid confident predictions on unfamiliar data has sparked interest in out-of-distribution (OOD) detection. It is widely assumed that Bayesian neural networks (BNN) are well suited for this task, as the endowed epistemic uncertainty should lead to disagreement in predictions on outliers. In this paper, we question this assumption and provide empirical evidence that proper Bayesian inference with common neural network architectures does not necessarily lead to good OOD detection. To circumvent the use of approximate inference, we start by studying the infinite-width case, where Bayesian inference can be exact considering the corresponding Gaussian process. Strikingly, the kernels induced under common architectural choices lead to uncertainties that do not reflect the underlying data generating process and are therefore unsuited for OOD detection. Finally, we study finite-width networks using HMC, and observe OOD behavior that is consistent with the infinite-width case. Overall, our study discloses fundamental problems when naively using BNNs for OOD detection and opens interesting avenues for future research.},
  annotation={* Equal contribution. Listing order is random.},
  additional_info={. *(Spotlight)*},
  abbr={ICML 2021 UDL},
  slides={bayesian_ood_talk_udl_2021_public.pdf},
}

@inproceedings{cervera:henning:2021:regression,
  bibtex_show={true},
  title={Uncertainty estimation under model misspecification in neural network regression},
  author={Maria R. Cervera* and Rafael Dätwyler* and Francesco D'Angelo* and Hamza Keurti* and Benjamin F. Grewe and Christian Henning},
  booktitle={NeurIPS Workshop on Robustness and misspecification in probabilistic modeling},
  year={2021},
  annotation={* Equal contribution. Listing order is random.},
  abstract={Although neural networks are powerful function approximators, the underlying modelling assumptions ultimately define the likelihood and thus the hypothesis class they are parameterizing. In classification, these assumptions are minimal as the commonly employed softmax is capable of representing any categorical distribution. In regression, however, restrictive assumptions on the type of continuous distribution to be realized are typically placed, like the dominant choice of training via mean-squared error and its underlying Gaussianity assumption. Recently, modelling advances allow to be agnostic to the type of continuous distribution to be modelled, granting regression the flexibility of classification models. While past studies stress the benefit of such flexible regression models in terms of performance, here we study the effect of the model choice on uncertainty estimation. We highlight that under model misspecification, aleatoric uncertainty is not properly captured, and that a Bayesian treatment of a misspecified model leads to unreliable epistemic uncertainty estimates. Overall, our study provides an overview on how modelling choices in regression may influence uncertainty estimation and thus any downstream decision making process.},
  arxiv={2111.11763},
  google_scholar_id={YsMSGLbcyi4C},
  code={https://github.com/mariacer/regression_uncertainty_mm},
  preview={hypothesis_space.png},
  additional_info={. *(Spotlight)*},
  abbr={NeurIPS 2021 Bayes},
}
% poster={missing-overleaf-compile-time}

@online{dangelo:henning:2021:uncertainty:based:ood,
  selected={true},
  bibtex_show={true},
  title={On out-of-distribution detection with Bayesian neural networks},
  author={Francesco D'Angelo* and Christian Henning*},
  year={2021},
  eprinttype={arXiv},
  google_scholar_id={W7OEmFMy1HYC},
  additional_info={*See also* our shorter [workshop paper](https://arxiv.org/abs/2107.12248)},
  dimensions={true},
  code={https://github.com/chrhenning/uncertainty_based_ood/tree/master},
  arxiv={2110.06020},
  preview={post_std_rbf.png},
  abstract={The question whether inputs are valid for the problem a neural network is trying to solve has sparked interest in out-of-distribution (OOD) detection. It is widely assumed that Bayesian neural networks (BNNs) are well suited for this task, as the endowed epistemic uncertainty should lead to disagreement in predictions on outliers. In this paper, we question this assumption and show that proper Bayesian inference with function space priors induced by neural networks does not necessarily lead to good OOD detection. To circumvent the use of approximate inference, we start by studying the infinite-width case, where Bayesian inference can be exact due to the correspondence with Gaussian processes. Strikingly, the kernels derived from common architectural choices lead to function space priors which induce predictive uncertainties that do not reflect the underlying input data distribution and are therefore unsuited for OOD detection. Importantly, we find the OOD behavior in this limiting case to be consistent with the corresponding finite-width case. To overcome this limitation, useful function space properties can also be encoded in the prior in weight space, however, this can currently only be applied to a specified subset of the domain and thus does not inherently extend to OOD data. Finally, we argue that a trade-off between generalization and OOD capabilities might render the application of BNNs for OOD detection undesirable in practice. Overall, our study discloses fundamental problems when naively using BNNs for OOD detection and opens interesting avenues for future research.},
  annotation={* Equal contribution. Listing order is random.},
}

@article{henning2022phdthesis,
  selected={true},
  bibtex_show={true},
  title={Knowledge uncertainty and lifelong learning in neural systems},
  author={Henning, Christian},
  year={2022},
  publisher={ETH Zurich},
  preview={pfcl_tempering1.png},
  html={https://www.research-collection.ethz.ch/handle/20.500.11850/523790},
  pdf={PhD_Thesis.pdf},
  google_scholar_id={eQOLeE2rZwMC},
  abstract={Natural intelligence has the ability to continuously learn from its environment, an environment that is constantly changing and thus induces uncertainties that need to be coped with to ensure survival. By contrast, artificial intelligence (AI) commonly learns from data only once during a particular training phase, and rarely explicitly represents or utilizes uncertainties. In this thesis, we contribute towards improving AI in these regards by designing and understanding neural network-based models that learn continually and that explicitly represent several sources of uncertainty, with the ultimate goal of obtaining models that are useful, reliable and practical. We start by setting this research into a broader context and providing an introduction to the fields of uncertainty estimation and continual learning. This detailed review can constitute an entry point for those interested in familiarizing themselves with these topics. After laying this foundation, we dive into the specific question of how to learn a set of tasks continually and present our approach for solving this problem based on a system of neural networks. More specifically, we train a meta-network to generate task-specific parameters for an inference model and show that, in this setting, forgetting can be prevented using a simple regularization at the meta-level. Due to the existence of task-specific solutions, the problem arises of having to infer the task to which an unseen input belongs. We investigate two major ways for solving this \emph{task-inference} problem: (i) replay-based and (ii) uncertainty-based. While replay-based task-inference exhibits remarkable performance on simple benchmarks, our implementation of this method relies on generative modelling, which becomes disproportionately difficult with increased task complexity. Uncertainty-based task-inference, on the other hand, does not rely on external models and scales more easily to complex scenarios. Because calibrating the uncertainties required for task-inference is difficult, in practice, one often resorts to models that should \emph{know what they don't know}. This can in theory be achieved through a Bayesian treatment of model parameters. However, due to the difficulty in  interpreting the prior knowledge given to a neural network-based model, it also becomes difficult to interpret what it is that the model \emph{knows not to know}. This realization has implications beyond continual learning, and more generally affects how current machine learning models handle unseen inputs. We discuss the intricacies associated with choosing prior knowledge in neural networks and show that common choices often lead to uncertainties that do not intrinsically reflect certain desiderata such as detecting unseen inputs that the model should not generalize to. Overall, this thesis compactly summarizes and contributes to the advancement of two important topics in nowadays deep learning research, uncertainty estimation and continual learning, while disclosing existing challenges, evaluating novel approaches and identifying promising avenues for future research.},
  additional_info={PhD Thesis},
}

@article{ehret2024population,
  bibtex_show={true},
  title={Population-level coding of avoidance learning in medial prefrontal cortex},
  author={Ehret, Benjamin and Boehringer, Roman and Amadei, Elizabeth A and Cervera, Maria R and Henning, Christian and Galgali, Aniruddh R and Mante, Valerio and Grewe, Benjamin F},
  journal={Nature Neuroscience},
  volume={27},
  number={9},
  pages={1805--1815},
  year={2024},
  publisher={Nature Publishing Group US New York},
  preview={population.jpg},
  doi={10.1038/s41593-024-01704-5},
  additional_info={. *See [this repo](https://github.com/chrhenning/experimental_setups) on information on how to build and control the experimental setup*},
  code={https://zenodo.org/records/11283463},
  google_scholar_id={LkGwnXOMwfcC},
  abstract={The medial prefrontal cortex (mPFC) has been proposed to link sensory inputs and behavioral outputs to mediate the execution of learned behaviors. However, how such a link is implemented has remained unclear. To measure prefrontal neural correlates of sensory stimuli and learned behaviors, we performed population calcium imaging during a new tone-signaled active avoidance paradigm in mice. We developed an analysis approach based on dimensionality reduction and decoding that allowed us to identify interpretable task-related population activity patterns. While a large fraction of tone-evoked activity was not informative about behavior execution, we identified an activity pattern that was predictive of tone-induced avoidance actions and did not occur for spontaneous actions with similar motion kinematics. Moreover, this avoidance-specific activity differed between distinct avoidance actions learned in two consecutive tasks. Overall, our results are consistent with a model in which mPFC contributes to the selection of goal-directed actions by transforming sensory inputs into specific behavioral outputs through distributed population-level computations.},
}

@article{henning2017masterthesis,
  bibtex_show={true},
  title={Estimating the Information Gap between Textual and Graphical Representations},
  author={Henning, Christian},
  year={2017},
  publisher={Leibniz University Hannover},
  preview={simple_classifier.JPG},
  pdf={master_thesis.pdf},
  additional_info={Master Thesis},
}

@article{henning2014bachelorthesis,
  bibtex_show={true},
  title={QBF-Solver},
  author={Henning, Christian},
  year={2014},
  publisher={Leibniz University Hannover},
  preview={bas-screenshot.png},
  pdf={henning-ba.pdf},
  additional_info={Bachelor Thesis},
  google_scholar_id={roLk4NBRz8UC},
}
